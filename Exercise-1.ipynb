{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMA4215 - Exercise 1 ## \n",
    "*Group: Hanna Simin Heshmati Rød, Karine Austbø Grande and Thea Boge*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1\n",
    "\n",
    "In this problem we want to determine whether the given mappings are vector norms. In order to determine whether the given mappings are vector norms, we need to verify if they satisfy the three properties of a norm:\n",
    "\n",
    "1. **Non-negativity**: $\\|x\\| \\geq 0$ for all $x \\in \\mathbb{R}^d$ and $\\|x\\| = 0$ if and only if $x = 0$.\n",
    "2. **Homogeneity**: $\\|\\alpha x\\| = |\\alpha| \\|x\\|$ for all $x \\in \\mathbb{R}^d$ and all scalars $\\alpha \\in \\mathbb{R}$.\n",
    "3. **Triangle inequality**: $\\|x + y\\| \\leq \\|x\\| + \\|y\\|$ for all $x, y \\in \\mathbb{R}^d$.\n",
    "\n",
    "### a) $\\|x\\|_{\\frac{1}{2}} := \\left( \\sum_{k=1}^d |x_k|^{\\frac{1}{2}} \\right)^2$\n",
    "\n",
    "1. **Non-negativity**: The expression $\\sum_{k=1}^d |x_k|^{\\frac{1}{2}}$ is non-negative because it is a sum of non-negative terms (absolute values raised to a positive power). Therefore, $\\|x\\|_{\\frac{1}{2}} \\geq 0$. However, $\\|x\\|_{\\frac{1}{2}} = 0$ if and only if $x_k = 0$ for all $k$, which means $x = 0$.\n",
    "\n",
    "2. **Homogeneity**: For any scalar $\\alpha \\in \\mathbb{R}$,\n",
    "\n",
    "   $\n",
    "   \\|\\alpha x\\|_{\\frac{1}{2}} = \\left( \\sum_{k=1}^d |\\alpha x_k|^{\\frac{1}{2}} \\right)^2 = \\left( |\\alpha|^{\\frac{1}{2}} \\sum_{k=1}^d |x_k|^{\\frac{1}{2}} \\right)^2 = |\\alpha| \\left( \\sum_{k=1}^d |x_k|^{\\frac{1}{2}} \\right)^2 = |\\alpha| \\|x\\|_{\\frac{1}{2}}.\n",
    "   $\n",
    "\n",
    "   This satisfies the homogeneity property.\n",
    "\n",
    "3. **Triangle inequality**: To check the triangle inequality for $\\|x\\|_{\\frac{1}{2}}$, consider two vectors $x, y \\in \\mathbb{R}^d$:\n",
    "\n",
    "   $\n",
    "   \\|x + y\\|_{\\frac{1}{2}} = \\left( \\sum_{k=1}^d |x_k + y_k|^{\\frac{1}{2}} \\right)^2.\n",
    "   $\n",
    "\n",
    "   The triangle equality likely fails. We can show by using a counterexample:\n",
    "   \n",
    "   Let $x = (1, 0)$ and $y = (0, 1)$ be our vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||x||_(1/2): 1.0\n",
      "||y||_(1/2): 1.0\n",
      "||x + y||_(1/2): 4.0\n",
      "The triangle inequality does not hold.\n",
      "4.0 is not less than or equal to 2.0\n"
     ]
    }
   ],
   "source": [
    "def norm_half(x):\n",
    "    return (sum(abs(xi)**0.5 for xi in x))**2\n",
    "\n",
    "# Test the triangle inequality with x = (1, 0) and y = (0, 1)\n",
    "x = [1, 0]\n",
    "y = [0, 1]\n",
    "\n",
    "# Compute norms\n",
    "norm_x = norm_half(x)\n",
    "norm_y = norm_half(y)\n",
    "norm_x_plus_y = norm_half([x[i] + y[i] for i in range(len(x))])\n",
    "\n",
    "# Print computed norms\n",
    "print(f\"||x||_(1/2): {norm_x}\")\n",
    "print(f\"||y||_(1/2): {norm_y}\")\n",
    "print(f\"||x + y||_(1/2): {norm_x_plus_y}\")\n",
    "\n",
    "# Check and print whether the triangle inequality holds\n",
    "if norm_x_plus_y <= norm_x + norm_y:\n",
    "    print(\"The triangle inequality holds.\")\n",
    "else:\n",
    "    print(\"The triangle inequality does not hold.\")\n",
    "    print(f\"{norm_x_plus_y} is not less than or equal to {norm_x + norm_y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) $\\|x\\|_0 := \\#\\{k : x_k \\neq 0\\}$ (the number of nonzero components of $x$)\n",
    "\n",
    "1. **Non-negativity**: $\\|x\\|_0 \\geq 0$ because it counts the number of non-zero components, which is always non-negative. $\\|x\\|_0 = 0$ if and only if $x = 0$ (all components are zero).\n",
    "\n",
    "2. **Homogeneity**: For any scalar $\\alpha \\neq 0$, $\\|\\alpha x\\|_0 = \\|x\\|_0$, since multiplying by a non-zero scalar does not change the number of non-zero components. However, for $\\alpha = 0$, $\\|0 \\cdot x\\|_0 = 0$, which is not equal to $|0| \\cdot \\|x\\|_0 = 0$. This violates the scalar multiplication property, so $\\|x\\|_0$ does not satisfy this condition for all scalars.\n",
    "\n",
    "3. **Triangle inequality**: $\\|x + y\\|_0 \\leq \\|x\\|_0 + \\|y\\|_0$ does not necessarily hold. For example, if $x = (1, 0)$ and $y = (0, 1)$, then $\\|x\\|_0 = 1$, $\\|y\\|_0 = 1$, but $\\|x + y\\|_0 = 2$. Hence, the triangle inequality is not satisfied.\n",
    "\n",
    "Therefore, $\\|x\\|_0$ is **not** a norm.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- $\\|x\\|_{\\frac{1}{2}}$ is **not** a norm because it fails the triangle inequality.\n",
    "- $\\|x\\|_0$ is **not** a norm because it fails the scalar multiplication property and the triangle inequality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "\n",
    "#### a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let V be the set of all $2x2$ real matrices. An arbitrary element A in V has the form $A = (\\begin{matrix} a & b \\\\ c & d \\end{matrix})$ where $a, b, c, d \\in \\mathbb{R} $.\n",
    "\n",
    "The set of 2x2 matrices forms a vector space if they satisfy the following vector space axioms:\n",
    "\n",
    "**1) Given two elements $A, B \\in V$, the sum $A+B \\in V$.**\n",
    "* $A + B = \\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) + \\biggl(\\begin{matrix} a_2 & b_2 \\\\ c_2 & d_2 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} a_1 + a_2 & b_1 + b_2 \\\\ c_1 + c_2 & d_1 + d_2 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} a_2 & b_2 \\\\ c_2 & d_2 \\end{matrix}\\biggr) + \\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) = B + A$\n",
    "* Since $a_1 + a_2, b_1 + b_2, c_1 + c_2, d_1 + d_2 \\in \\mathbb{R} $, the sum $A + B$ is a real $2x2$ matrix, $A + B \\in \\mathbb{R}$. \n",
    "\n",
    "**2) $A + B = B + A$, also shown above.**\n",
    "\n",
    "**3) For any $A, B, C \\in V, (A + B) + C = A + (B + C)$**\n",
    "* This holds because matrix addition is associative. \n",
    "* $(A + B) + C = \\biggl(\\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) + \\biggl(\\begin{matrix} a_2 & b_2 \\\\ c_2 & d_2 \\end{matrix}\\biggr)\\biggr) +  \\biggl(\\begin{matrix} a_3 & b_3 \\\\ c_3 & d_3 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} a_1 + a_2 + a_3  & b_1 + b_2 + b_3 \\\\ c_1 + c_2 + c_3 & d_1 + d_2 + d_3 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) + \\biggl(\\biggl(\\begin{matrix} a_2 & b_2 \\\\ c_2 & d_2 \\end{matrix}\\biggr) +  \\biggl(\\begin{matrix} a_3 & b_3 \\\\ c_3 & d_3 \\end{matrix}\\biggr)\\biggr) = A + (B + C) $\n",
    "\n",
    "**4) There exist a zero matrix $0 \\in V$ such that for any $A \\in V, A + 0 = A$.**\n",
    "* $A + 0 = \\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) + \\biggl(\\begin{matrix} 0 & 0 \\\\ 0 & 0 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) = A$\n",
    "\n",
    "**5) For all $A \\in V$ there exists a $-A$ such that $A + (-A) = 0$.**\n",
    "* $A + (-A) = \\biggl(\\begin{matrix} a_1 & b_1 \\\\ c_1 & d_1 \\end{matrix}\\biggr) + \\biggl(\\begin{matrix} - a_1 & - b_1 \\\\ - c_1 & - d_1 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} a_1 - a_1 & b_1 - b_1 \\\\ c_1 - c_1 & d_1 - d_1 \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} 0 & 0 \\\\ 0 & 0 \\end{matrix}\\biggr) $\n",
    "\n",
    "**6) For any element $A \\in V$ and any scalar $\\lambda \\in \\mathbb{R}$ the product $A\\lambda \\in V$.**\n",
    "* $\\lambda A = \\lambda \\biggl(\\begin{matrix} a & b \\\\ c & d \\end{matrix}\\biggr) = \\biggl(\\begin{matrix} \\lambda a & \\lambda b \\\\ \\lambda c & \\lambda d \\end{matrix}\\biggr)$\n",
    "* Since $\\lambda a, \\lambda b, \\lambda c, \\lambda d \\in \\mathbb{R} $, the product $\\lambda A$ is a real $2x2$ matrix, $\\lambda A \\in \\mathbb{R}$\n",
    "\n",
    "**7) For any element $A$ and $B$ $ \\in V$ and any scalar $\\alpha$ $ \\in \\mathbb{R}$, $\\alpha (A + B) = \\alpha A + \\alpha B$**\n",
    "\n",
    "**8) For any element $A \\in V$ and any scalars $\\alpha$ and $\\beta$ $ \\in \\mathbb{R}$, $(\\alpha)\\beta A = (\\alpha\\beta) A$**\n",
    "\n",
    "**9) For any element $A \\in V$ and any scalars $\\alpha$ and $\\beta$ $ \\in \\mathbb{R}$, $(\\alpha + \\beta) A = \\alpha A + \\beta A$**\n",
    "\n",
    "* These distributive properties (7, 8 and 9) hold because matrix multiplication y scalars and atrix addition satisfy them. \n",
    "\n",
    "**10) There exists a matrix $I$ such that $AI = A$**\n",
    "* This is known to be the identity matrix $I = \\biggl(\\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}\\biggr)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "\n",
    "To show that $(A,B) = trace(AB^T)$ defines an inner product on the vector space of $2x2$ real matrices we need to verify that it satisfies the four properties of an inner product.\n",
    "\n",
    "*1) $\\langle \\lambda A + C, B \\rangle = \\lambda \\langle A,C\\rangle + \\langle B,C\\rangle$(linearity)*\n",
    "\n",
    "* Trace is the sum of the diagonal elements of a matrix. Since \n",
    "\\begin{equation}\n",
    "trace(X + Y) = trace(X) + trace (Y), trace(\\lambda X) = \\lambda trace(X)\n",
    "\\end{equation}\n",
    "for every $X, Y \\in \\mathbb{R^{nxn}} and \\lambda \\in \\mathbb{R}.$ We have\n",
    "\\begin{equation} \n",
    "\\langle \\lambda A + C, B \\rangle = trace(C^T (\\lambda A + B)) = trace(\\lambda C^T  A + C^T B) = \\lambda trace(C^T A) + trace(C^T B) = \\lambda \\langle A,C\\rangle + \\langle B,C\\rangle\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "*2) $\\langle A,B \\rangle = \\langle B,A \\rangle$ (symmetry)*\n",
    "\n",
    "* Since \n",
    "\\begin{equation}\n",
    "trace(X^T) = trace(X) \n",
    "\\end{equation}\n",
    "for every $X, Y \\in \\mathbb{R^{nxn}} and \\lambda \\in \\mathbb{R}.$ We have\n",
    "\\begin{equation}\n",
    "\\langle A,B \\rangle = trace(B^T A) = trace((B^T A)^T) = trace(A^T B) = \\langle B,A \\rangle\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "*3) $\\langle A,A \\rangle > 0$ unless $A=0$ (definiteness)*\n",
    "* For every $A=(A_{ij})$ \\in \\mathbb{R^{mxn}}$ we have\n",
    "\\begin{equation} \n",
    "\\langle A, A \\rangle = trace(A^TA) = \\sum_{i=1}^{n} (A^T A)_{ij} = \\sum{i=1}^{n}\\sum_{j=1}^{n} A^T_{ij} A_{ji} = \\sum{i=1}^{n}\\sum_{j=1}^{n} A^2_{ij} \\geq 0\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation} \n",
    "\\langle A, A \\rangle = \\sum{i=1}^{n}\\sum_{j=1}^{n} A^2_{ij} = 0 \\Leftrightarrow (A_{ij} = 0  \\forall  i,j) \\Leftrightarrow A = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "\n",
    "#### a)\n",
    "A matrix $A \\in \\mathbb{R}^{n \\times n}$ is orthogonal if $A^{T}A = I$\n",
    "We are looking for matrixes wich also satisfies $(A^2)^{T}A^2 = I$\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "(A^2)^{T}A^2 = (A  A)^{T}  A = A^{T}  A^{T}  A  A = (A^{T}  A)  (A^{T}  A) = I   I = I\n",
    "\n",
    "\\end{equation}\n",
    "\n",
    "This shows that for any orthogonal matrices A, the matrix $A^2$ also is orthogonal.\n",
    "\n",
    "#### b)\n",
    "We have an orthogonal matrix $A$ and $B$, we are no going to prove that the product of $A$ and $B$ is also orthogonal.\n",
    "\n",
    "$A A^{T} = I$\n",
    "and\n",
    "$B B^{T} = I$\n",
    "\n",
    "We need to show that $ (AB)^{T}  AB = I$\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "(AB)^{T} AB = B^{T} A^{T} A B = B^{T} (A^{T} A) B = B^{T} I B = B^{T} B = I\n",
    "\\end{equation}\n",
    "\n",
    "We have then proven that the product of two orthogonal matrices always i orthogonal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "A matrix is normal if it is commutes with its own conjugate transpose.\n",
    "\n",
    "Counterexample:\n",
    "We have to normal matrices $A$ and $B$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "A matrix is normal if it is commutes with its own conjugate transpose.\n",
    "\n",
    "Counterexample:\n",
    "We have to normal matrices $A$ and $B$\n",
    "\n",
    "\\begin{equation}\n",
    "A = \\begin{bmatrix} 1 & 0\\\\ 0 & 2 \\end{bmatrix},\n",
    "B = \\begin{bmatrix} 0 & 1\\\\ 1 & 0 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Verify that $A$ is normal:\n",
    "\n",
    "\\begin{equation}\n",
    "A^{T} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Compute $A^{T}A$ and $AA^{T}$\n",
    "\n",
    "\\begin{equation}\n",
    "A^{T}A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 4 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "AA^{T} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 4 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Since $A^{T}A = AA^{T}$, A is normal\n",
    "\n",
    "Verify that $B$ is normal:\n",
    "\n",
    "\\begin{equation}\n",
    "B^{T} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Compute $B^{T}B$ and $BB^{T}$\n",
    "\\begin{equation}\n",
    "B^{T}B = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = I\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "BB^{T} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = I\n",
    "\\end{equation}\n",
    "\n",
    "Since $B^{T}B = BB^{T}$, $B$ is normal\n",
    "The product $AB$:\n",
    "\n",
    "$ AB = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix} \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 2 & 0 \\end{bmatrix} $\n",
    "\n",
    "The transpose of $AB$:\n",
    "\n",
    "$(AB)^{T} = \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} $\n",
    "\n",
    "Check if AB is normal:\n",
    "\n",
    "$(AB)^{T} (AB) = \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} 0 & 1 \\\\ 2 & 0 \\end{bmatrix} = \\begin{bmatrix} 4 & 0 \\\\ 0 & 1 \\end{bmatrix} $\n",
    "\n",
    "$ (AB) (AB)^{T} = \\begin{bmatrix} 0 & 1 \\\\ 2 & 0 \\end{bmatrix} \\begin{bmatrix} 0 & 2 \\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 4 \\end{bmatrix} $\n",
    "\n",
    "\n",
    "Since $(AB)^{T} (AB) \\neq (AB) (AB)^{T}$ the matrix AB is not normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4\n",
    "#### a)\n",
    "$J_{n}$ is a symmetric tridiagonal matrix, and the determinant of $J_{n}$ satisifes the followin recurrence relation:\n",
    "\\begin{equation}\n",
    "det(J_{n}-xI) = (x- \\alpha_{n})det(J_{n-1} - xI) - \\beta_{n}det(J_{n} - xI)\n",
    "\\end{equation}\n",
    "\n",
    "We can see that this is the same recurrance relation as the one givenfor $p_{n}(x)$\n",
    "\\begin{equation}\n",
    "p_{n}(x) = (x-\\alpha_{n})p_{n-1}(x) + \\beta_{n}p_{n-2}(x)\n",
    "\\end{equation}\n",
    "\n",
    "The characteristic polynomial of $J_{n}$ satisifies the same recurrence relation as $p_{n}(x)$ it follows that\n",
    "\\begin{equation}\n",
    "det(J_{n}-xI) = p_{n}(x)\n",
    "\\end{equation}\n",
    "\n",
    "The eigenvalues of the matrix $J_n$ is given by solving $det(J_{n}-xI) = 0$, the zeros of $p_{n}(x)$ is given by solving $P_{n}(x) = 0$.\n",
    "Since we have $det(J_{n}-xI) = p_{n}(x)$, the eigenvalues of $J_{n}$ is the same as the zeros of $p_{n}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
